{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBJflajTYUJv",
    "outputId": "1ca2e26e-0362-489c-fa14-48dbefbd73b8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import pipeline_utilities as p_util\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset nowildfire\n",
      "Loading validation dataset wildfire\n"
     ]
    }
   ],
   "source": [
    "dir = '../Project_3/Resources/valid/'\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "for direct in os.listdir(dir):\n",
    "    print(\"Loading validation dataset {}\".format(direct))\n",
    "    for filename in os.listdir(os.path.join(dir,direct)):\n",
    "        img_path = os.path.join(dir,direct,filename)\n",
    "#        print(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((32,32))\n",
    "        img = np.array(img)\n",
    "        img = img/255\n",
    "        X_valid.append(img)\n",
    "        if direct == 'wildfire':\n",
    "            y_valid.append(1)\n",
    "        else:\n",
    "            y_valid.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing dataset nowildfire\n",
      "Loading testing dataset wildfire\n"
     ]
    }
   ],
   "source": [
    "dir = '../Project_3/Resources/test/'\n",
    "X_test = []\n",
    "y_test = []\n",
    "for direct in os.listdir(dir):\n",
    "    print(\"Loading testing dataset {}\".format(direct))\n",
    "    for filename in os.listdir(os.path.join(dir,direct)):\n",
    "        img_path = os.path.join(dir,direct,filename)\n",
    "#        print(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((32,32))\n",
    "        img = np.array(img)\n",
    "        img = img/255\n",
    "        X_test.append(img)\n",
    "        if direct == 'wildfire':\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset nowildfire\n",
      "../Project_3/Resources/train/nowildfire\\-114.152378,51.027198.jpg\n",
      "Loading training dataset wildfire\n"
     ]
    }
   ],
   "source": [
    "dir = '../Project_3/Resources/train/'\n",
    "X_train = []\n",
    "y_train = []\n",
    "for direct in os.listdir(dir):\n",
    "    print(\"Loading training dataset {}\".format(direct))\n",
    "    for filename in os.listdir(os.path.join(dir,direct)):\n",
    "        img_path = os.path.join(dir,direct,filename)\n",
    "#        print(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        try:\n",
    "            img = img.resize((32,32))\n",
    "            img = np.array(img)\n",
    "            img = img/255\n",
    "            X_train.append(img)\n",
    "            if direct == 'wildfire':\n",
    "                y_train.append(1)\n",
    "            else:\n",
    "                y_train.append(0)\n",
    "        except:\n",
    "            print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset images\n"
     ]
    }
   ],
   "source": [
    "dir = '../Project_3/Resources/jonathan/'\n",
    "X_jon_test = []\n",
    "y_jon_test = []\n",
    "for direct in os.listdir(dir):\n",
    "    print(\"Loading training dataset {}\".format(direct))\n",
    "    for filename in os.listdir(os.path.join(dir,direct)):\n",
    "        img_path = os.path.join(dir,direct,filename)\n",
    "#        print(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        try:\n",
    "            img = img.resize((32,32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = np.array(img)\n",
    "            img = img/255\n",
    "            X_jon_test.append(img)\n",
    "            y_jon_test.append(1)\n",
    "        except:\n",
    "            print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30249, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_valid = np.array(X_valid)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_valid = np.array(y_valid)\n",
    "X_jon_test = np.array(X_jon_test)\n",
    "y_jon_test = np.array(y_jon_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m295,040\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,782,529</span> (6.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,782,529\u001b[0m (6.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,781,313</span> (6.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,781,313\u001b[0m (6.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Build the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')  # Output layer with number of classes\n",
    "])\n",
    "\n",
    "# Step 2: Compile the model\n",
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Loss function for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 251ms/step - accuracy: 0.8739 - loss: 0.3067 - val_accuracy: 0.8973 - val_loss: 0.3703\n",
      "Epoch 2/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 245ms/step - accuracy: 0.9182 - loss: 0.2097 - val_accuracy: 0.8179 - val_loss: 0.4235\n",
      "Epoch 3/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 217ms/step - accuracy: 0.9263 - loss: 0.1885 - val_accuracy: 0.7627 - val_loss: 0.4506\n",
      "Epoch 4/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 210ms/step - accuracy: 0.9312 - loss: 0.1814 - val_accuracy: 0.6225 - val_loss: 1.0639\n",
      "Epoch 5/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 209ms/step - accuracy: 0.9352 - loss: 0.1708 - val_accuracy: 0.9405 - val_loss: 0.1788\n",
      "Epoch 6/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 211ms/step - accuracy: 0.9421 - loss: 0.1547 - val_accuracy: 0.9256 - val_loss: 0.1953\n",
      "Epoch 7/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 209ms/step - accuracy: 0.9451 - loss: 0.1465 - val_accuracy: 0.9554 - val_loss: 0.1241\n",
      "Epoch 8/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 212ms/step - accuracy: 0.9484 - loss: 0.1376 - val_accuracy: 0.8362 - val_loss: 0.3488\n",
      "Epoch 9/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 212ms/step - accuracy: 0.9512 - loss: 0.1326 - val_accuracy: 0.9519 - val_loss: 0.1467\n",
      "Epoch 10/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 210ms/step - accuracy: 0.9539 - loss: 0.1257 - val_accuracy: 0.8800 - val_loss: 0.2606\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9596 - loss: 0.1018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2593678832054138, 0.8850611448287964]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.2279 - loss: 1.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9666813611984253, 0.23181377351284027]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(X_jon_test, y_jon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30249, 3072)\n",
      "(6299, 3072)\n",
      "(6300, 3072)\n",
      "(30249,)\n",
      "(6299,)\n",
      "(6300,)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "X_valid_flatten = X_valid.reshape(X_valid.shape[0], -1)\n",
    "print(X_train_flatten.shape)\n",
    "print(X_test_flatten.shape)\n",
    "print(X_valid_flatten.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Data Score: 0.8973519785778042\n",
      "Logistic Regression Testing Data Score: 0.8866486743927607\n",
      "Logistic Regression Predictions Accuracy Score: 0.8866486743927607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.90      0.90      3479\n",
      "           0       0.87      0.87      0.87      2820\n",
      "\n",
      "    accuracy                           0.89      6299\n",
      "   macro avg       0.89      0.89      0.89      6299\n",
      "weighted avg       0.89      0.89      0.89      6299\n",
      "\n",
      "Logistic Regression Balanced Accuracy Score: 0.8853606950721553\n",
      "Logistic Regression roc_auc_score: 0.9523178325379856\n"
     ]
    }
   ],
   "source": [
    "# Create and fit a Logistic Regression model\n",
    "random_state = 1\n",
    "p_util.logistic_regression_model_generator(X_train_flatten, X_test_flatten, y_train, y_test, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Data Score: 0.8973519785778042\n",
      "Logistic Regression Testing Data Score: 0.7643064985451018\n",
      "Logistic Regression Predictions Accuracy Score: 0.7643064985451018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.76      0.87      1031\n",
      "           0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.76      1031\n",
      "   macro avg       0.50      0.38      0.43      1031\n",
      "weighted avg       1.00      0.76      0.87      1031\n",
      "\n",
      "Logistic Regression Balanced Accuracy Score: 0.7643064985451018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression roc_auc_score: 0.9523178325379856\n"
     ]
    }
   ],
   "source": [
    "# Trying out a Logistic Regression model on Jonathan's wildfire test images\n",
    "X_jon_test_flatten = X_jon_test.reshape(X_jon_test.shape[0], -1)\n",
    "print(X_jon_test_flatten.shape)\n",
    "random_state = 1\n",
    "p_util.logistic_regression_model_generator(X_train_flatten, X_jon_test_flatten, y_train, y_jon_test, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Data Score: 0.9999669410559027\n",
      "Random Forest Testing Data Score: 0.9107794888077473\n",
      "Random Forest Predictions Accuracy Score: 0.9107794888077473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.89      0.92      3479\n",
      "           0       0.88      0.93      0.90      2820\n",
      "\n",
      "    accuracy                           0.91      6299\n",
      "   macro avg       0.91      0.91      0.91      6299\n",
      "weighted avg       0.91      0.91      0.91      6299\n",
      "\n",
      "Random Forest Balanced Accuracy Score: 0.9129155887707195\n"
     ]
    }
   ],
   "source": [
    "# Trying a random forest model on wildfire image data\n",
    "random_state = 1\n",
    "n_estimators = 100\n",
    "p_util.random_forest_model_generator(X_train_flatten, X_test_flatten, y_train, y_test, random_state, n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Data Score: 0.9999669410559027\n",
      "Random Forest Testing Data Score: 0.6207565470417071\n",
      "Random Forest Predictions Accuracy Score: 0.6207565470417071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.62      0.77      1031\n",
      "           0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62      1031\n",
      "   macro avg       0.50      0.31      0.38      1031\n",
      "weighted avg       1.00      0.62      0.77      1031\n",
      "\n",
      "Random Forest Balanced Accuracy Score: 0.6207565470417071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kalas\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "# Let's try Random Forest model on Jonathan's images \n",
    "p_util.random_forest_model_generator(X_train_flatten, X_jon_test_flatten, y_train, y_jon_test, random_state, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Data Score: 1.0\n",
      "Decision Tree Testing Data Score: 0.8458485473884744\n",
      "Decision Tree Predictions Accuracy Score: 0.8458485473884744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.84      0.86      3479\n",
      "           0       0.81      0.85      0.83      2820\n",
      "\n",
      "    accuracy                           0.85      6299\n",
      "   macro avg       0.84      0.85      0.84      6299\n",
      "weighted avg       0.85      0.85      0.85      6299\n",
      "\n",
      "Decision Tree Balanced Accuracy Score: 0.8465104201704655\n"
     ]
    }
   ],
   "source": [
    "# Trying a decision tree model\n",
    "p_util.decision_tree_model_generator(X_train_flatten, X_test_flatten, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Training Data Score: 1.0\n",
      "Extra Trees Testing Data Score: 0.9115732655977139\n",
      "Extra Trees Predictions Accuracy Score: 0.9115732655977139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.92      0.92      3479\n",
      "           0       0.90      0.90      0.90      2820\n",
      "\n",
      "    accuracy                           0.91      6299\n",
      "   macro avg       0.91      0.91      0.91      6299\n",
      "weighted avg       0.91      0.91      0.91      6299\n",
      "\n",
      "Extra Trees Balanced Accuracy Score: 0.9104099775960729\n"
     ]
    }
   ],
   "source": [
    "# Trying an extra trees model\n",
    "random_state = 1\n",
    "p_util.extra_trees_model_generator(X_valid_flatten, X_test_flatten, y_valid, y_test, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boosting Training Data Score: 0.8812192138583094\n",
      "Ada Boosting Testing Data Score: 0.891093824416574\n",
      "Ada Boosting Predictions Accuracy Score: 0.891093824416574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.89      0.90      3479\n",
      "           0       0.87      0.89      0.88      2820\n",
      "\n",
      "    accuracy                           0.89      6299\n",
      "   macro avg       0.89      0.89      0.89      6299\n",
      "weighted avg       0.89      0.89      0.89      6299\n",
      "\n",
      "Ada Boosting Balanced Accuracy Score: 0.890996944177731\n"
     ]
    }
   ],
   "source": [
    "# Trying an ADA boost model\n",
    "random_state = 1\n",
    "p_util.ada_boost_model_generator(X_train_flatten, X_test_flatten, y_train, y_test, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Training Data Score: 0.9657142857142857\n",
      "Gradient Boosting Testing Data Score: 0.9104619780917605\n",
      "Gradient Boosting Predictions Accuracy Score: 0.9104619780917605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.93      0.92      3479\n",
      "           0       0.91      0.89      0.90      2820\n",
      "\n",
      "    accuracy                           0.91      6299\n",
      "   macro avg       0.91      0.91      0.91      6299\n",
      "weighted avg       0.91      0.91      0.91      6299\n",
      "\n",
      "Gradient Boosting Balanced Accuracy Score: 0.9085978892605888\n"
     ]
    }
   ],
   "source": [
    "# This model took forever to run, not sure if it ever finished, changed train to valid data set\n",
    "random_state = 1\n",
    "p_util.gradient_boost_model_generator(X_valid_flatten, X_test_flatten, y_valid, y_test, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training Data Score: 0.9561904761904761\n",
      "SVM Testing Data Score: 0.8490236545483411\n",
      "SVM Predictions Accuracy Score: 0.8490236545483411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.90      0.87      3479\n",
      "           0       0.86      0.79      0.82      2820\n",
      "\n",
      "    accuracy                           0.85      6299\n",
      "   macro avg       0.85      0.84      0.85      6299\n",
      "weighted avg       0.85      0.85      0.85      6299\n",
      "\n",
      "SVM Balanced Accuracy Score: 0.8433058329714864\n",
      "CPU times: total: 43.6 s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kernel_type = 'linear'\n",
    "p_util.svm_model_generator(X_valid_flatten, X_test_flatten, y_valid, y_test, kernel_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 - Get NYT articles on wildfires\n",
    "\n",
    "# Import dependencies\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "import spacy\n",
    "# Load the English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables and New York Times API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"NYTIMES_API_KEY\")\n",
    "type(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New York Times Article API URL\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "\n",
    "# Search for articles that mention granola\n",
    "query = \"wildfire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query URL\n",
    "query_url = url + \"api-key=\" + api_key + \"&q=\" + query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request articles\n",
    "articles = requests.get(query_url).json()\n",
    "\n",
    "# The \"response\" property in articles contains the actual articles\n",
    "# list comprehension.\n",
    "articles_list = articles[\"response\"][\"docs\"]\n",
    "#print(json.dumps(articles_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nytimes.com/2024/11/20/nyregion/new-york-wildfires-drought.html\n",
      "https://www.nytimes.com/2024/11/24/opinion/wildfires-new-york-new-jersey-prescribed-burn.html\n",
      "https://www.nytimes.com/2024/11/18/opinion/wildfires-new-jersey-new-york-climate-change.html\n",
      "https://www.nytimes.com/video/weather/100000009824708/inwood-hill-new-york-fire.html\n",
      "https://www.nytimes.com/video/weather/100000009818664/wildfires-northeast-us.html\n",
      "https://www.nytimes.com/2024/11/11/nyregion/jennings-creek-wildfire-ny-nj.html\n",
      "https://www.nytimes.com/2024/11/12/nyregion/jennings-creek-wildfire-nj-ny-wind.html\n",
      "https://www.nytimes.com/2024/11/10/nyregion/orange-county-fire-sterling-forest.html\n",
      "https://www.nytimes.com/video/us/100000009812041/california-wildfires.html\n",
      "https://www.nytimes.com/2024/11/04/weather/california-wind-wildfires.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The New York region is unlikely to ever have as many brush fires as out West. But residents need to be ready for more droughts.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the web_url of each stored article\n",
    "texts = []\n",
    "for article in articles_list:\n",
    "    print(article[\"web_url\"])\n",
    "    texts.append(article[\"snippet\"])\n",
    "    texts.append(article[\"lead_paragraph\"])\n",
    "\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the most_common_adjs function to tokenize the text, creates a list of with all the adjectives, \n",
    "# and retrieve the most common adjectives and their frequency. \n",
    "def most_common_adjs(text):\n",
    "    \"\"\"\n",
    "    Finds and returns the most common adjective in the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text from which adjectives will be extracted.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the most common adjectives and their frequency.\n",
    "               The tuple has the format (adjective, frequency).\n",
    "\n",
    "    Example:\n",
    "    >>> text = \"The quick brown fox jumps over the lazy dog. The fast fox is brown.\"\n",
    "    >>> most_common_adj(text)\n",
    "    ('brown', 2)\n",
    "    \"\"\"\n",
    "    # Tokenizes text and parse each token\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Creates a list with all the adjectives in the text\n",
    "    adjs = [token.text.lower() for token in doc if token.pos_ == 'ADJ']\n",
    "    \n",
    "    # Retrieves the most frequent adjective in the adjectives list using the Counter module\n",
    "    try:\n",
    "        most_common_adj = Counter(adjs).most_common(1)[0]\n",
    "        return most_common_adj\n",
    "    except:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('unlikely', 1), None, ('prescribed', 1), ('active', 1), ('hard', 1), None, None, None, ('dry', 1), ('dry', 1), None, ('vast', 1), ('rugged', 1), None, ('latest', 1), ('old', 1), ('strong', 1), ('strong', 1), ('multiple', 1), ('dangerous', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the most common adjective for wildfire articles\n",
    "common_adjs = [most_common_adjs(text) for text in texts]\n",
    "\n",
    "# Print the common adjectives.\n",
    "print(common_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dry', 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltext = \"\"\n",
    "for text in texts:\n",
    "    alltext += text + \" \"\n",
    "most_common_adjs(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying conversational memory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# Store the API key in a variable.\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three common causes of wildfires are:\n",
      "\n",
      "1. **Lightning strikes:**  Natural ignition sources, particularly during dry thunderstorms.\n",
      "2. **Human carelessness:** This is the most common cause, encompassing things like discarded cigarettes, unattended campfires, equipment malfunctions (like chainsaws), and power lines sparking.\n",
      "3. **Arson:** Deliberately set fires, often for malicious reasons.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.3)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are three common causes of wildfire?\"\n",
    "\n",
    "# Pass the query to the invoke method, and print the result.\n",
    "result = llm.invoke(query)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preventive precautions depend heavily on *what* you're trying to prevent.  To give you helpful advice, I need more context.  Are you trying to prevent:\n",
      "\n",
      "* **A specific illness or disease?** (e.g., the flu, COVID-19, heart disease, cancer)  Please specify the illness.\n",
      "* **An accident or injury?** (e.g., a car accident, a fall, a fire) Please specify the type of accident.\n",
      "* **Damage to property?** (e.g., theft, flooding, fire) Please specify the type of damage.\n",
      "* **A security breach?** (e.g., hacking, identity theft) Please specify the type of breach.\n",
      "* **Something else entirely?** Please describe the situation.\n",
      "\n",
      "\n",
      "Once you provide more details, I can offer specific and useful preventive precautions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What preventive precautions should be taken?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk of wildfire in a specific region presents several marketing opportunities, depending on the target audience and the type of business.  These opportunities can be broadly categorized into:\n",
      "\n",
      "**I.  Mitigation & Prevention:**\n",
      "\n",
      "* **Home Protection Products & Services:**  Marketing fire-resistant roofing materials, landscaping services specializing in fire-safe vegetation, sprinkler systems, defensible space creation, and security systems with early wildfire detection capabilities.  Focus on the peace of mind and property protection offered.\n",
      "* **Insurance Products:**  Marketing specialized wildfire insurance policies, emphasizing coverage for property damage, liability, and relocation costs.  Highlight the increasing risk and the importance of adequate coverage.\n",
      "* **Community Preparedness Programs:**  Marketing workshops, educational materials, and community events focused on wildfire preparedness, evacuation planning, and emergency response.  This could target homeowners associations, local governments, and schools.\n",
      "* **Technology Solutions:**  Marketing wildfire monitoring and alert systems, including apps, sensors, and drone services that provide early warnings and real-time information.  Emphasize the speed and accuracy of the technology.\n",
      "\n",
      "\n",
      "**II.  Recovery & Rebuilding:**\n",
      "\n",
      "* **Construction & Renovation Services:**  Marketing services for rebuilding homes and businesses destroyed by wildfires.  Highlight expertise in fire-resistant construction and rapid response times.\n",
      "* **Disaster Relief Services:**  Marketing temporary housing, cleanup services, debris removal, and other essential services needed in the aftermath of a wildfire.  Focus on speed, efficiency, and compassion.\n",
      "* **Financial Services:**  Marketing loans, grants, and insurance claims assistance specifically for wildfire victims.  Emphasize streamlined processes and support during a difficult time.\n",
      "* **Mental Health Services:**  Marketing counseling and support services for individuals and communities affected by wildfires.  Highlight the importance of mental well-being after trauma.\n",
      "\n",
      "\n",
      "**III.  Awareness & Education:**\n",
      "\n",
      "* **Public Service Announcements (PSAs):**  Partnering with government agencies and non-profits to create and distribute PSAs about wildfire prevention and preparedness.\n",
      "* **Educational Campaigns:**  Developing and marketing educational materials, such as brochures, websites, and videos, to raise public awareness about wildfire risks and mitigation strategies.\n",
      "* **Environmental Conservation Initiatives:**  Marketing sustainable forestry practices, controlled burns, and other initiatives to reduce wildfire risk.  Appeal to environmentally conscious consumers.\n",
      "\n",
      "\n",
      "**Marketing Strategies:**\n",
      "\n",
      "* **Targeted Advertising:**  Use geographic targeting to reach residents in high-risk areas.\n",
      "* **Social Media Marketing:**  Utilize social media platforms to share information, engage with communities, and promote products and services.\n",
      "* **Partnerships:**  Collaborate with local businesses, government agencies, and non-profits to expand reach and credibility.\n",
      "* **Content Marketing:**  Create valuable content, such as blog posts, articles, and videos, to educate and inform potential customers.\n",
      "* **Emotional Appeals:**  Use imagery and storytelling to connect with audiences on an emotional level and highlight the importance of preparedness and recovery.\n",
      "\n",
      "\n",
      "**Ethical Considerations:**\n",
      "\n",
      "It's crucial to avoid exploiting the fear and vulnerability of wildfire victims.  Marketing efforts should be sensitive, responsible, and focus on providing genuine value and support.  Transparency and honesty in pricing and service delivery are essential.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Based on the risk of wildfire occurring in a specific region, what marketing opportunties exist?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for conversational memory.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalas\\AppData\\Local\\Temp\\ipykernel_25768\\964137067.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  buffer = ConversationBufferMemory()\n",
      "C:\\Users\\kalas\\AppData\\Local\\Temp\\ipykernel_25768\\964137067.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm, verbose=True, memory=buffer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What are three common causes of wildfire?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Three common causes of wildfires are lightning strikes, human carelessness, and equipment malfunctions.\n",
      "\n",
      "Let's break those down a bit further:\n",
      "\n",
      "* **Lightning Strikes:**  These are a natural cause, often occurring during dry thunderstorms where there's little to no rain to extinguish the resulting fire.  The intense heat and energy from a lightning bolt can ignite dry brush, grass, and trees, especially in areas with abundant dry fuel.  The location and intensity of the strike significantly impact the resulting fire's size and spread.\n",
      "\n",
      "* **Human Carelessness:** This is a broad category encompassing a wide range of activities.  The most common culprits include:\n",
      "    * **Unattended campfires:**  Failing to properly extinguish a campfire before leaving it can easily lead to a wildfire, especially in windy conditions or dry vegetation.\n",
      "    * **Discarded cigarettes:**  A carelessly tossed cigarette butt can smolder and ignite dry grass or leaves, particularly in areas with low humidity.\n",
      "    * **Debris burning:**  Escaped debris burns are a frequent cause, often fueled by strong winds or unexpected changes in weather conditions.  Lack of proper permits and safety precautions contribute significantly to this.\n",
      "    * **Power lines:**  Faulty or downed power lines can spark and ignite nearby vegetation.  This is more common during periods of high winds or extreme weather events.\n",
      "    * **Arson:**  Intentionally set fires are a serious and dangerous cause of wildfires.\n",
      "\n",
      "\n",
      "* **Equipment Malfunctions:**  This includes a variety of equipment, most notably:\n",
      "    * **Agricultural machinery:**  Overheated machinery, such as tractors or harvesters, can ignite dry fields.  Sparks from equipment can also ignite dry grass or other flammable materials.\n",
      "    * **Chainsaws and other power tools:**  These tools can generate sparks that can ignite dry vegetation, especially in hot and dry conditions.  Improper maintenance or use increases the risk.\n",
      "    * **Vehicles:**  Overheated catalytic converters or exhaust systems can ignite dry grass along roadsides.\n",
      "\n",
      "\n",
      "It's important to note that the relative contribution of each cause varies depending on geographical location, climate, and time of year.  In some areas, lightning strikes are the dominant cause, while in others, human activity plays a much larger role.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What are three common causes of wildfire?\n",
      "AI: Three common causes of wildfires are lightning strikes, human carelessness, and equipment malfunctions.\n",
      "\n",
      "Let's break those down a bit further:\n",
      "\n",
      "* **Lightning Strikes:**  These are a natural cause, often occurring during dry thunderstorms where there's little to no rain to extinguish the resulting fire.  The intense heat and energy from a lightning bolt can ignite dry brush, grass, and trees, especially in areas with abundant dry fuel.  The location and intensity of the strike significantly impact the resulting fire's size and spread.\n",
      "\n",
      "* **Human Carelessness:** This is a broad category encompassing a wide range of activities.  The most common culprits include:\n",
      "    * **Unattended campfires:**  Failing to properly extinguish a campfire before leaving it can easily lead to a wildfire, especially in windy conditions or dry vegetation.\n",
      "    * **Discarded cigarettes:**  A carelessly tossed cigarette butt can smolder and ignite dry grass or leaves, particularly in areas with low humidity.\n",
      "    * **Debris burning:**  Escaped debris burns are a frequent cause, often fueled by strong winds or unexpected changes in weather conditions.  Lack of proper permits and safety precautions contribute significantly to this.\n",
      "    * **Power lines:**  Faulty or downed power lines can spark and ignite nearby vegetation.  This is more common during periods of high winds or extreme weather events.\n",
      "    * **Arson:**  Intentionally set fires are a serious and dangerous cause of wildfires.\n",
      "\n",
      "\n",
      "* **Equipment Malfunctions:**  This includes a variety of equipment, most notably:\n",
      "    * **Agricultural machinery:**  Overheated machinery, such as tractors or harvesters, can ignite dry fields.  Sparks from equipment can also ignite dry grass or other flammable materials.\n",
      "    * **Chainsaws and other power tools:**  These tools can generate sparks that can ignite dry vegetation, especially in hot and dry conditions.  Improper maintenance or use increases the risk.\n",
      "    * **Vehicles:**  Overheated catalytic converters or exhaust systems can ignite dry grass along roadsides.\n",
      "\n",
      "\n",
      "It's important to note that the relative contribution of each cause varies depending on geographical location, climate, and time of year.  In some areas, lightning strikes are the dominant cause, while in others, human activity plays a much larger role.\n",
      "\n",
      "Human: What preventive measures should be taken?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Preventing wildfires requires a multi-pronged approach focusing on both individual responsibility and broader community efforts.  Here are some key preventive measures:\n",
      "\n",
      "**Individual Actions:**\n",
      "\n",
      "* **Campfire Safety:**  Always clear a 10-foot area around your campfire down to bare earth.  Never leave a campfire unattended, and ensure it's completely extinguished with water and stirred ashes before leaving the area.  Check local regulations for campfire permits and restrictions.\n",
      "\n",
      "* **Safe Cigarette Disposal:**  Never throw cigarette butts out of car windows or leave them lying around.  Always extinguish them completely in an ashtray or other fire-safe container.\n",
      "\n",
      "* **Debris Burning:**  Check local regulations and obtain necessary permits before burning debris.  Never burn on windy days or when vegetation is dry.  Have water and tools readily available to control the fire, and never leave a debris burn unattended.\n",
      "\n",
      "* **Maintaining Equipment:**  Regularly inspect and maintain all equipment, particularly those that generate sparks or heat, such as lawnmowers, chainsaws, and vehicles.  Ensure proper functioning of catalytic converters and exhaust systems.\n",
      "\n",
      "* **Fireworks Safety:**  Use fireworks only when and where legally permitted and always follow safety instructions carefully.  Never use fireworks near dry vegetation.\n",
      "\n",
      "* **Vehicle Safety:**  Be aware of the potential for hot exhaust systems and catalytic converters to ignite dry grass, especially when driving on or near dry vegetation.\n",
      "\n",
      "**Community and Governmental Actions:**\n",
      "\n",
      "* **Fuel Management:**  Controlled burns and forest thinning can reduce the amount of flammable material available to fuel wildfires.  This is often done by forestry agencies and land management organizations.\n",
      "\n",
      "* **Public Education Campaigns:**  Raising public awareness about wildfire prevention through educational programs and public service announcements is crucial.\n",
      "\n",
      "* **Early Warning Systems:**  Implementing and maintaining effective early warning systems, including weather monitoring and fire detection technologies, allows for quicker response times.\n",
      "\n",
      "* **Improved Infrastructure:**  Maintaining and upgrading power lines and other infrastructure to minimize the risk of equipment-related fires is essential.\n",
      "\n",
      "* **Enforcement of Regulations:**  Strict enforcement of regulations related to campfire permits, debris burning, and other fire-related activities is necessary to deter irresponsible behavior.\n",
      "\n",
      "* **Community Wildfire Protection Plans:**  Developing and implementing community-specific wildfire protection plans that address local risks and vulnerabilities is vital.  These plans often involve community-wide efforts in fuel reduction and evacuation planning.\n",
      "\n",
      "\n",
      "It's important to remember that wildfire prevention is an ongoing process requiring continuous vigilance and cooperation between individuals, communities, and governing bodies.  The specific measures needed will vary depending on the local environment and risk factors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.3)\n",
    "\n",
    "# Initialize an object for conversational memory.\n",
    "buffer = ConversationBufferMemory()\n",
    "\n",
    "# Create the chain for conversation, using a ConversationBufferMemory object.\n",
    "conversation = ConversationChain(llm=llm, verbose=True, memory=buffer)\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What are three common causes of wildfire?\"\n",
    "\n",
    "# Pass the query to the predict method and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)\n",
    "\n",
    "print()\n",
    "\n",
    "# Define a query as a string.\n",
    "query = \"What preventive measures should be taken?\"\n",
    "\n",
    "# Pass the query to the predict method, and print the result.\n",
    "result = conversation.predict(input=query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
