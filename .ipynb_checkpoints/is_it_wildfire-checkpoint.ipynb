{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBJflajTYUJv",
    "outputId": "1ca2e26e-0362-489c-fa14-48dbefbd73b8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import json\n",
    "from PIL import Image\n",
    "import pipeline_utilities as p_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of image filenames\n",
    "image_filenames = ['Resources/nowildfire/-113.917243,51.101323.jpg',\n",
    "                   'Resources/nowildfire/-113.917264,50.966686.jpg',\n",
    "                   'Resources/nowildfire/-113.917465,51.051057.jpg',\n",
    "                   'Resources/nowildfire/-113.917555,51.071225.jpg',\n",
    "                   'Resources/nowildfire/-113.917557,51.165343.jpg',\n",
    "                   'Resources/yeswildfire/-57.11902,51.47242.jpg',\n",
    "                   'Resources/yeswildfire/-58.657,51.1945.jpg',\n",
    "                   'Resources/yeswildfire/-58.71402,51.32554.jpg',\n",
    "                   'Resources/yeswildfire/-58.81589,51.78597.jpg',\n",
    "                   'Resources/yeswildfire/-60.6867,50.26079.jpg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list of images\n",
    "images = []\n",
    "\n",
    "# Loop through all image filenames to open and append each image\n",
    "for i in range(len(image_filenames)):\n",
    "\n",
    "    # Append each image to the images list\n",
    "    images.append(Image.open(image_filenames[i]))\n",
    "\n",
    "# View the first image to confirm\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sizes into a list, then convert to a set\n",
    "sizes = set([img.size for img in images])\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all images to floating point numpy arrays\n",
    "float_images = [np.array(img).astype(np.float32) for img in images]\n",
    "\n",
    "# Display the pixel values of the first image\n",
    "print(\"Pixel Values:\")\n",
    "print(float_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize pixel values to a range between 0 and 1,\n",
    "# we need to divide all color pixel values by the max of 255\n",
    "\n",
    "normalized_images = [img/255 for img in float_images]\n",
    "\n",
    "# Display the pixel values of the first image\n",
    "print(\"Pixel Values:\")\n",
    "print(normalized_images[0])\n",
    "normalized_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_processed_df = pd.DataFrame({\"Wildfire\": [0,0,0,0,0,1,1,1,1,1]})\n",
    "y_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X to a numpy array\n",
    "X = np.array(normalized_images)\n",
    "#X_flatten = X.reshape(X.shape[2], -1).T\n",
    "\n",
    "# Loop through each image to include the channel dimension\n",
    "X_processed = []\n",
    "for img in X:\n",
    "    # Add channel dimension\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "    # Append the image to the array\n",
    "    X_processed.append(img)\n",
    "\n",
    "# Split X and y into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flatten, y_processed_df)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed_df)\n",
    "X_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a Logistic Regression model\n",
    "random_state = 1\n",
    "p_util.logistic_regression_model_generator(X_train, X_test, y_train, y_test, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
